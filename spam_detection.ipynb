{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1BJSk6iCj1J",
        "outputId": "d9025e66-63a8-4da2-e313-d24a28d0fc8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /home/ujjwal/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/ujjwal/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/ujjwal/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/ujjwal/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAdpNbeKCj1M"
      },
      "source": [
        "### Reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TYc4zmzB8I1l"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"dataset/train_df.csv\")\n",
        "df_test = pd.read_csv(\"dataset/test_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhWGgcpW19MH",
        "outputId": "77f1ef2b-f87b-4f75-c6e4-f0156c0e9646"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000000, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFDzCXliCj1O"
      },
      "source": [
        "Finding duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03d8CIXXCj1O",
        "outputId": "660d3460-b235-4601-8594-5ece802cb205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_train[df_train.duplicated()])\n",
        "len(df_test[df_test.duplicated()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0GMkPdAWCj1P"
      },
      "outputs": [],
      "source": [
        "troll_questions = df_train['target'][df_train['target'] == 1].index\n",
        "genuine_questions = df_train['target'][df_train['target'] == 0].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnFKaYtPCj1P",
        "outputId": "26b8749d-3668-4564-b533-2bba9fe3ca77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15.162922256343947"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(genuine_questions)/len(troll_questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGdoryD6GgWY"
      },
      "source": [
        "## VECTORIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F2XlD6y7fYNc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validate, Y_train, Y_validate = train_test_split(df_train['question_text'], df_train['target'], test_size=0.1, train_size=0.9, shuffle=True)\n",
        "\n",
        "X_test = df_test[\"question_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vlw7h6Fu0-y",
        "outputId": "eb5e31ec-750d-44f3-f732-e913d85a84fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43412     If you could tell one thing to your 10 year ol...\n",
              "69323     How is the placement department at BMSCE Banga...\n",
              "762053                             Who discovered eletrons?\n",
              "608276    What do smart students do for timepass on inte...\n",
              "876809    Why should you not bring too much money in you...\n",
              "Name: question_text, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_validate.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1FXUZJsu2wD",
        "outputId": "d84e7e49-f013-437e-c5de-0b7b96658213"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "656554    0\n",
              "609948    0\n",
              "89026     0\n",
              "176332    0\n",
              "946346    0\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_validate.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dgYBoyEw7p-",
        "outputId": "5ccd3770-3c52-4da9-ded4-d768571fb4ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "978548                 How do I love a woman that loves me?\n",
              "861936         What weight air hostess should have and age?\n",
              "31594     Is there any meat that cannot be eaten or is d...\n",
              "457591                       What is the AIIMS UG syllabus?\n",
              "893069    Why is the price of Mishra Dhatu Nigam stock s...\n",
              "                                ...                        \n",
              "221513    Could Harrison Wells or Devoe from the Flash p...\n",
              "316272    Why is it when I sign up for a class at a coll...\n",
              "938623    Why aren't Muslim community ashamed of their h...\n",
              "333430    Was Stephen Hawking battling depression toward...\n",
              "147664         Who decided to kill John Fitzgerald Kennedy?\n",
              "Name: question_text, Length: 900000, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zRN9IpKFGTxm"
      },
      "outputs": [],
      "source": [
        "# # from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# # We can change the number of words counted together and see results on accuracy\n",
        "# # CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
        "\n",
        "# # vectorizer = CountVectorizer()\n",
        "\n",
        "# # X_train = vectorizer.fit_transform(question_text_train.values.astype('U'))\n",
        "# Y_train = df_train['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nuxzxMtAsiBb"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# # # We can change the number of words counted together and see results on accuracy\n",
        "# # # CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
        "\n",
        "# tfidf = TfidfVectorizer(\n",
        "#     strip_accents = 'unicode',\n",
        "#     analyzer = 'word',\n",
        "#     ngram_range = (1, 1),\n",
        "#     max_features = 150000\n",
        "# )\n",
        "# tfidf.fit(df_train['question_text'])\n",
        "\n",
        "# X_train1 = tfidf.transform(X_train)\n",
        "# X_validate1 = tfidf.transform(X_validate)\n",
        "# X_test1 = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dmNdBlIJ-OpH"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# # from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# # We can change the number of words counted together and see results on accuracy\n",
        "# CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    strip_accents = 'unicode',\n",
        "    analyzer = 'word',\n",
        "    ngram_range = (1, 3),\n",
        "    max_df = 0.5,\n",
        "    max_features = 150000,\n",
        ")\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    strip_accents = 'unicode',\n",
        "    analyzer = 'char',\n",
        "    ngram_range = (1, 3),\n",
        "    max_df = 0.5,\n",
        "    max_features = 150000,\n",
        ")\n",
        "\n",
        "# # tfidf = TfidfVectorizer()\n",
        "\n",
        "X_train1_wv = word_vectorizer.fit_transform(X_train.values.astype('U'))\n",
        "X_validate1_wv = word_vectorizer.transform(X_validate.values.astype('U'))\n",
        "\n",
        "X_train1_cv = char_vectorizer.fit_transform(X_train.values.astype('U'))\n",
        "X_validate1_cv = char_vectorizer.transform(X_validate.values.astype('U'))\n",
        "# # X_train = tfidf.fit(X_train)\n",
        "\n",
        "X_train1 = hstack((X_train1_wv, X_train1_cv)).tocsr()\n",
        "X_validate1 = hstack((X_validate1_wv, X_validate1_cv)).tocsr()\n",
        "\n",
        "\n",
        "X_test1_wv = word_vectorizer.transform(X_test)\n",
        "X_test1_cv = char_vectorizer.transform(X_test)\n",
        "\n",
        "X_test1 = hstack((X_test1_wv, X_test1_cv)).tocsr()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx44C3Ou_I1M"
      },
      "source": [
        "# BALANCING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsfwxivNAve2"
      },
      "source": [
        "## Over-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-W8ewg5r_Kbd"
      },
      "outputs": [],
      "source": [
        "# from collections import Counter\n",
        "# from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UqvFfAt0_Kzs"
      },
      "outputs": [],
      "source": [
        "# ros = RandomOverSampler(random_state=42)\n",
        "# X_train1, Y_train = ros.fit_resample(X_train1, Y_train)\n",
        "# X_validate1, Y_validate = ros.fit_resample(X_validate1, Y_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9Y1lfQRrWoCr"
      },
      "outputs": [],
      "source": [
        "# sm = SMOTE(random_state=42)\n",
        "# X_train1, Y_train = sm.fit_resample(X_train1, Y_train)\n",
        "# X_validate1, Y_validate = sm.fit_resample(X_validate1, Y_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MVZMhGBQAM-0"
      },
      "outputs": [],
      "source": [
        "# X_train1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uy9H9ILAz7f"
      },
      "source": [
        "## Under-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "akddOKm4AzBs"
      },
      "outputs": [],
      "source": [
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# ros = RandomUnderSampler(random_state=42)\n",
        "# X_train1, Y_train = ros.fit_resample(X_train1, Y_train)\n",
        "# X_validate1, Y_validate = ros.fit_resample(X_validate1, Y_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "deAYv52aBI5P"
      },
      "outputs": [],
      "source": [
        "# X_train1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2DTCylsAEm-"
      },
      "source": [
        "# GENERATING MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlW5Jn4hCj1Y"
      },
      "source": [
        "## MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of31NC43Cj1Y"
      },
      "source": [
        "## 2. Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ixGBEDMwf9bK"
      },
      "outputs": [],
      "source": [
        "# multi_naive_bayes_model = MultinomialNB()\n",
        "\n",
        "# multi_naive_bayes_model.fit(X_train1, Y_train)\n",
        "\n",
        "# Y_pred_mnb = multi_naive_bayes_model.predict(X_validate1)\n",
        "# pred_MNB = metrics.f1_score(Y_validate, Y_pred_mnb)\n",
        "\n",
        "# print(f\"Multinomial Naive Bayes: {pred_MNB}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KiRcZ9aIgKlr"
      },
      "outputs": [],
      "source": [
        "# Y_pred_mnb = multi_naive_bayes_model.predict(X_test1)\n",
        "\n",
        "# # result_target = pd.DataFrame(Y_pred_mnb, columns=['target'])\n",
        "# # question_id = df_test['qid']\n",
        "\n",
        "# # result = pd.concat([question_id, result_target], axis=1, join='inner')\n",
        "\n",
        "# # result.to_csv(\"seventh_submission_CV_multiNB.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5woS4ln4Cj1Z"
      },
      "source": [
        "## 3. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VN0rH1eBgN_F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression  : 0.6391398491749422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ujjwal/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "logistic_regression_model = LogisticRegression(\n",
        "    dual = False,\n",
        "    class_weight = {0: 0.23, 1: 0.77}\n",
        ")\n",
        "logistic_regression_model.fit(X_train1, Y_train)\n",
        "\n",
        "Y_pred_lr = logistic_regression_model.predict(X_validate1)\n",
        "pred_LR = metrics.f1_score(Y_validate, Y_pred_lr)\n",
        "\n",
        "print(f\"Logistic Regression  : {pred_LR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNpm-61pCHjR"
      },
      "source": [
        "### Changing Threshold of Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E82JOm-bPPU3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression  : 0.6336361134048996\n"
          ]
        }
      ],
      "source": [
        "def custom_predict(X, threshold):\n",
        "    probs = logistic_regression_model.predict_proba(X) \n",
        "    return (probs[:, 1] > threshold).astype(int)\n",
        "    \n",
        "Y_pred_lr = custom_predict(X=X_validate1, threshold=0.425)\n",
        "pred_LR = metrics.f1_score(Y_validate, Y_pred_lr)\n",
        "\n",
        "print(f\"Logistic Regression  : {pred_LR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFganBjFX4yt"
      },
      "source": [
        "### Confusion Matrix for different Class-Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vK4GUFQeXZyX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[90072,  3766],\n",
              "       [ 1558,  4604]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(Y_validate, Y_pred_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c4IDVdDiX32y"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/home/ujjwal/.local/lib/python3.8/site-packages/sklearn/metrics/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_confusion_matrix\n\u001b[1;32m      4\u001b[0m color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m matrix \u001b[38;5;241m=\u001b[39m plot_confusion_matrix(logistic_regression_model, X_validate1, Y_validate, cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/home/ujjwal/.local/lib/python3.8/site-packages/sklearn/metrics/__init__.py)"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        " \n",
        "# color = 'white'\n",
        "# matrix = plot_confusion_matrix(logistic_regression_model, X_validate1, Y_validate, cmap=plt.cm.Blues)\n",
        "# matrix.ax_.set_title('Confusion Matrix', color=color)\n",
        "# plt.xlabel('Predicted Label', color=color)\n",
        "# plt.ylabel('True Label', color=color)\n",
        "# plt.gcf().axes[0].tick_params(colors=color)\n",
        "# plt.gcf().axes[1].tick_params(colors=color)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOQ75IHhsGu9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rffawTFCrC7j"
      },
      "outputs": [],
      "source": [
        "Y_pred_lr = logistic_regression_model.predict(X_test1)\n",
        "\n",
        "# Updating the classification based on new threshold\n",
        "Y_pred_lr = custom_predict(X=X_test1, threshold=0.39)\n",
        "\n",
        "result_target = pd.DataFrame(Y_pred_lr, columns=['target'])\n",
        "question_id = df_test['qid']\n",
        "\n",
        "result = pd.concat([question_id, result_target], axis=1, join='inner')\n",
        "\n",
        "result.to_csv(\"50th_submission_tuning_threshold_LR.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3q4UOzw9oiws"
      },
      "outputs": [],
      "source": [
        "# print(\"f1-score using:\\n\")\n",
        "# print(f\"Multinomial Naive Bayes: {pred_MNB}\")\n",
        "# print(f\"Logistic Regression    : {pred_LR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE-KIv2Stndm"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IdD5aZdmtpQU"
      },
      "outputs": [],
      "source": [
        "# svc_model = LinearSVC(dual=False, class_weight={0: 0.23, 1: 0.77})\n",
        "# svc_model.fit(X_train1, Y_train)\n",
        "\n",
        "# Y_pred_svc = svc_model.predict(X_validate1)\n",
        "# pred_SVC = metrics.f1_score(Y_validate, Y_pred_svc)\n",
        "\n",
        "# print(f\"Linear Support Vector: {pred_SVC}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0Uoj5vRdD5W3"
      },
      "outputs": [],
      "source": [
        "# Y_pred_svc = svc_model.predict(X_test1)\n",
        "\n",
        "# result_target = pd.DataFrame(Y_pred_svc, columns=['target'])\n",
        "# question_id = df_test['qid']\n",
        "\n",
        "# result = pd.concat([question_id, result_target], axis=1, join='inner')\n",
        "\n",
        "# result.to_csv(\"eleventh_submission_vectorizer_SVC.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx_NPK4avf7E"
      },
      "source": [
        "## VOTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oLkmeYoUoHd"
      },
      "source": [
        "### Trying to vote results of models: Multinomial Naive Bayes, Logistic Regression, Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hvz9E90mUnSH"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# def changeToYesNo(x):\n",
        "#   if x > 1:\n",
        "#     return 1\n",
        "#   else:\n",
        "#     return 0 \n",
        "\n",
        "# Y_sum = Y_pred_mnb + Y_pred_lr + Y_pred_svc\n",
        "\n",
        "# mixed_pred = np.array([changeToYesNo(x) for x in Y_sum])\n",
        "\n",
        "# # mixed_pred = metrics.f1_score(Y_validate, Y_sum)\n",
        "# # print(f\"Mixed Prediction: {mixed_pred}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eL5Pqpygeb1x"
      },
      "outputs": [],
      "source": [
        "# result_target = pd.DataFrame(mixed_pred, columns=['target'])\n",
        "# question_id = df_test['qid']\n",
        "\n",
        "# result = pd.concat([question_id, result_target], axis=1, join='inner')\n",
        "\n",
        "# result.to_csv(\"seventeen_submission_vectorizer_SVC.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdiLBcIStrYP"
      },
      "source": [
        "## BAGGING ENSEMBLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yJ5HaUVytvUK"
      },
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "# from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# clf = BaggingClassifier(base_estimator=SVC(),n_estimators=10, random_state=0)\n",
        "# clf.fit(X_train1, Y_train)\n",
        "\n",
        "# Y_pred_bagging = clf.predict(X_validate1)\n",
        "# pred_bagging = metrics.f1_score(Y_validate, Y_pred_bagging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "La8g8ge_uMge"
      },
      "outputs": [],
      "source": [
        "# print(f\"Bagging ensemble: {pred_bagging}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taRsniCHmygA"
      },
      "source": [
        "## XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jNypQHiSnN6V"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# boost_model = GradientBoostingClassifier()\n",
        "# boost_model.fit(X_train1, Y_train)\n",
        "\n",
        "# Y_pred_boost = boost_model.predict(X_validate1)\n",
        "# pred_boost = metrics.f1_score(Y_validate, Y_pred_boost)\n",
        "\n",
        "# print(pred_boost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22pnVD3vwWeE"
      },
      "source": [
        "## RANDOM FOREST CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Dqcq1aYzwbEh"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "I0d06-uxwy1E"
      },
      "outputs": [],
      "source": [
        "# pred_rfc = 0.00  # in case the model is not run\n",
        "\n",
        "# rfc_model = RandomForestClassifier(\n",
        "#   class_weight= {0: 0.23, 1: 0.77}\n",
        "# )\n",
        "\n",
        "# rfc_model.fit(X_train1, Y_train)\n",
        "\n",
        "# pred = rfc_model.predict(X_validate1)\n",
        "# pred_rfc = metrics.f1_score(Y_validate, pred)\n",
        "\n",
        "# print(f\"Random Forest Classifier: {pred_rfc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NNKjAHAEQ-Y"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lMXb0yXAEAhP"
      },
      "outputs": [],
      "source": [
        "# print(\"f1-score using:\\n\")\n",
        "# print(f\"Multinomial Naive Bayes : {pred_MNB}\")\n",
        "# print(f\"Logistic Regression     : {pred_LR}\")\n",
        "# print(f\"Linear Support Vector   : {pred_SVC}\")\n",
        "# print(f\"Random Forest Classifier: {pred_rfc}\")\n",
        "# print(f\"XG Boost                : {pred_boost}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WhCj5gnpz_Jt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wlW5Jn4hCj1Y"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
